{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# URL langsung\n",
        "URL_ORIG = \"https://drive.usercontent.google.com/download?id=1StM28VCyWsO_MQnxNn5lNm7xugqq-FDs&export=download&authuser=0&confirm=t&uuid=e073f0ba-18a3-4d64-bb61-2f7aabe5aadc&at=AKSUxGPlb1TnAwAeu18-3oUtk25f%3A1762002831851\"\n",
        "URL_FAKE = \"https://drive.usercontent.google.com/download?id=1YIRG3BMOCvSNYqN5llRe7EUZn0yMq4GI&export=download&authuser=1&confirm=t&uuid=9b598e74-500e-4b68-be6e-2a190884ece7&at=AKSUxGPSeC79xkvr9ZU-X2SzXtIV%3A1762003073715\"\n",
        "\n",
        "# Direktori target\n",
        "ROOT    = \"/content/FFPP_LOCAL\"\n",
        "OUT_DIR = \"/content/project\"\n",
        "\n",
        "# LIMIT video yang diekstrak (ringan)\n",
        "LIMIT_REAL = 10\n",
        "LIMIT_FAKE = 10\n",
        "\n",
        "for p in [ROOT, OUT_DIR]:\n",
        "    Path(p).mkdir(parents=True, exist_ok=True)\n",
        "print(\"ROOT:\", ROOT, \"| OUT_DIR:\", OUT_DIR)\n",
        "print(\"LIMIT_REAL:\", LIMIT_REAL, \"| LIMIT_FAKE:\", LIMIT_FAKE)\n"
      ],
      "metadata": {
        "id": "ppvcE36wozK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash -s \"$URL_ORIG\" \"$URL_FAKE\" \"$LIMIT_REAL\" \"$LIMIT_FAKE\"\n",
        "set -euo pipefail\n",
        "TMP=\"/content/_zip_tmp\"\n",
        "ROOT=\"/content/FFPP_LOCAL\"\n",
        "URL_ORIG=\"$1\"\n",
        "URL_FAKE=\"$2\"\n",
        "LIM_REAL=\"$3\"\n",
        "LIM_FAKE=\"$4\"\n",
        "\n",
        "mkdir -p \"$TMP\" \\\n",
        "         \"$ROOT/original_sequences/youtube/c23/videos\" \\\n",
        "         \"$ROOT/manipulated_sequences/Deepfakes/c23/videos\"\n",
        "\n",
        "echo \"[Download]\"\n",
        "wget -O \"$TMP/original.zip\" --no-verbose --timeout=180 \"$URL_ORIG\"\n",
        "wget -O \"$TMP/deepfakes.zip\" --no-verbose --timeout=180 \"$URL_FAKE\"\n",
        "\n",
        "echo \"[Selective unzip REAL]\"\n",
        "rm -rf \"$TMP/original\"; mkdir -p \"$TMP/original\"\n",
        "mapfile -t REALS < <(unzip -Z1 \"$TMP/original.zip\" | grep -i \"\\.mp4$\" | head -n \"$LIM_REAL\")\n",
        "for f in \"${REALS[@]}\"; do\n",
        "  unzip -o \"$TMP/original.zip\" \"$f\" -d \"$TMP/original\" >/dev/null || true\n",
        "done\n",
        "\n",
        "echo \"[Selective unzip FAKE]\"\n",
        "rm -rf \"$TMP/deepfakes\"; mkdir -p \"$TMP/deepfakes\"\n",
        "mapfile -t FAKES < <(unzip -Z1 \"$TMP/deepfakes.zip\" | grep -i \"\\.mp4$\" | head -n \"$LIM_FAKE\")\n",
        "for f in \"${FAKES[@]}\"; do\n",
        "  unzip -o \"$TMP/deepfakes.zip\" \"$f\" -d \"$TMP/deepfakes\" >/dev/null || true\n",
        "done\n",
        "\n",
        "echo \"[Move MP4s -> FF++]\"\n",
        "find \"$TMP/original\"  -type f \\( -iname \"*.mp4\" -o -iname \"*.MP4\" \\) -exec cp -n \"{}\" \"$ROOT/original_sequences/youtube/c23/videos\"/ \\;\n",
        "find \"$TMP/deepfakes\" -type f \\( -iname \"*.mp4\" -o -iname \"*.MP4\" \\) -exec cp -n \"{}\" \"$ROOT/manipulated_sequences/Deepfakes/c23/videos\"/ \\;\n",
        "\n",
        "echo \"[Counts]\"\n",
        "echo -n \"real: \"; ls \"$ROOT/original_sequences/youtube/c23/videos\" 2>/dev/null | wc -l || true\n",
        "echo -n \"fake: \"; ls \"$ROOT/manipulated_sequences/Deepfakes/c23/videos\" 2>/dev/null | wc -l || true"
      ],
      "metadata": {
        "id": "d7MqL-9Uozxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "ROOT=\"/content/FFPP_LOCAL\"\n",
        "n_real=len(glob.glob(f\"{ROOT}/original_sequences/youtube/c23/videos/*.mp4\"))\n",
        "n_fake=len(glob.glob(f\"{ROOT}/manipulated_sequences/Deepfakes/c23/videos/*.mp4\"))\n",
        "print(\"real:\", n_real, \"| fake:\", n_fake)\n",
        "assert n_real>0 and n_fake>0, \"Video real/fake tidak ditemukan (cek URL/ZIP atau LIMIT terlalu kecil).\"\n"
      ],
      "metadata": {
        "id": "M7mRcv8xpJCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U ultralytics opencv-python scikit-learn tensorflow\n"
      ],
      "metadata": {
        "id": "PtLOXqkxuLtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prepare_data.py\n",
        "import os, glob, random, cv2\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# versi ringan\n",
        "FPS_SAMPLE = 1              # lebih jarang ambil frame\n",
        "IMG_SIZE = (299,299)\n",
        "CONF_THRES = 0.25\n",
        "MAX_CROPS_PER_VIDEO = 20    # batasi crop\n",
        "random.seed(42)\n",
        "\n",
        "def _yolo():\n",
        "    return YOLO(\"yolov8n-face.pt\") if Path(\"yolov8n-face.pt\").exists() else YOLO(\"yolov8n.pt\")\n",
        "\n",
        "def extract_frames(vpath:Path, out_dir:Path, fps_sample=FPS_SAMPLE):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "    cap=cv2.VideoCapture(str(vpath))\n",
        "    if not cap.isOpened(): return 0\n",
        "    fps=cap.get(cv2.CAP_PROP_FPS) or 30\n",
        "    interval=max(1, round(fps/fps_sample))\n",
        "    i=saved=0\n",
        "    while True:\n",
        "        ret,frame=cap.read()\n",
        "        if not ret: break\n",
        "        if i%interval==0:\n",
        "            cv2.imwrite(str(out_dir/f\"frame_{i:06d}.jpg\"), frame); saved+=1\n",
        "        i+=1\n",
        "    cap.release(); return saved\n",
        "\n",
        "def crop_faces(frames_dir:Path, yolo, conf=CONF_THRES, max_per_video=MAX_CROPS_PER_VIDEO):\n",
        "    crops=[]; frames=sorted(frames_dir.glob(\"*.jpg\")); random.shuffle(frames)\n",
        "    for f in frames:\n",
        "        img=cv2.imread(str(f));\n",
        "        if img is None: continue\n",
        "        res=yolo(img, conf=conf, verbose=False)[0]\n",
        "        for b in res.boxes.xyxy.cpu().numpy():\n",
        "            x1,y1,x2,y2=map(int,b[:4]); face=img[y1:y2,x1:x2]\n",
        "            if face.size==0: continue\n",
        "            face=cv2.resize(face, IMG_SIZE, interpolation=cv2.INTER_LANCZOS4)\n",
        "            crops.append(face)\n",
        "            if len(crops)>=max_per_video: return crops\n",
        "    return crops\n",
        "\n",
        "def run(root:str, out:str):\n",
        "    root=Path(root); out=Path(out)\n",
        "    frames_dir=out/\"data_frames\"; crops_dir=out/\"data_crops\"\n",
        "    for sp in [\"train\",\"val\",\"test\"]:\n",
        "        for c in [\"real\",\"fake\"]:\n",
        "            (crops_dir/sp/c).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    real = [(p, p.stem) for p in (root/\"original_sequences/youtube/c23/videos\").glob(\"*.mp4\")]\n",
        "    fake = [(p, \"Deepfakes_\"+p.stem) for p in (root/\"manipulated_sequences/Deepfakes/c23/videos\").glob(\"*.mp4\")]\n",
        "    assert real and fake, \"Video real/fake tidak ditemukan.\"\n",
        "\n",
        "    def split(ids):\n",
        "        tr,tmp=train_test_split(ids, test_size=0.3, random_state=42)\n",
        "        va,te=train_test_split(tmp, test_size=0.5, random_state=42)\n",
        "        return set(tr), set(va), set(te)\n",
        "    tr_r, va_r, te_r = split([vid for _,vid in real])\n",
        "    tr_f, va_f, te_f = split([vid for _,vid in fake])\n",
        "\n",
        "    yolo=_yolo()\n",
        "    counts={\"train\":0,\"val\":0,\"test\":0}\n",
        "    for name,lst in [(\"real\",real),(\"fake\",fake)]:\n",
        "        for vpath,vid in lst:\n",
        "            if (name==\"real\" and vid in tr_r) or (name==\"fake\" and vid in tr_f): sp=\"train\"\n",
        "            elif (name==\"real\" and vid in va_r) or (name==\"fake\" and vid in va_f): sp=\"val\"\n",
        "            else: sp=\"test\"\n",
        "            fdir=frames_dir/name/vid\n",
        "            if not fdir.exists() or not list(fdir.glob(\"*.jpg\")):\n",
        "                n=extract_frames(vpath,fdir,FPS_SAMPLE); print(f\"[extract] {vpath.name} -> {n} frames\")\n",
        "            faces=crop_faces(fdir,yolo,CONF_THRES,MAX_CROPS_PER_VIDEO)\n",
        "            for i,im in enumerate(faces):\n",
        "                cv2.imwrite(str((crops_dir/sp/name/f\"{vid}_{i:03d}.jpg\")), im)\n",
        "            counts[sp]+=len(faces); print(f\"[{sp}/{name}] {vid}: {len(faces)} crops\")\n",
        "    print(\"Selesai. Counts:\", counts)\n"
      ],
      "metadata": {
        "id": "rzPsIhT2uhwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import prepare_data\n",
        "prepare_data.run(root=\"/content/FFPP_LOCAL\", out=\"/content/project\")\n"
      ],
      "metadata": {
        "id": "aapx7emMuiIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "base=\"/content/project/data_crops\"\n",
        "print(\"data_crops exists:\", os.path.isdir(base))\n",
        "for sp in [\"train\",\"val\",\"test\"]:\n",
        "    for c in [\"real\",\"fake\"]:\n",
        "        print(f\"{sp:5s} {c:5s} ->\", len(glob.glob(f\"{base}/{sp}/{c}/*.jpg\")))\n"
      ],
      "metadata": {
        "id": "qwyUMa6kukPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_xception_tf.py\n",
        "import tensorflow as tf, os\n",
        "from tensorflow.keras import layers, models\n",
        "# Pastikan Anda mengimpor preprocess_input yang benar\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# --- 1. KONFIGURASI DAN SETUP ---\n",
        "# BATCH: 32 adalah titik awal yang baik. EPOCHS: 100\n",
        "IMG_SIZE=(299,299); BATCH=32; EPOCHS=100\n",
        "DATA_DIR=os.environ.get(\"DATA_DIR\",\"/content/project/data_crops\")\n",
        "MODEL_DIR=os.environ.get(\"MODEL_DIR\",\"/content/project/models\")\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# --- 2. FUNGSI DATASET ---\n",
        "def ds(split, shuffle=True):\n",
        "    # Menggunakan tf.keras.utils.image_dataset_from_directory (API Modern)\n",
        "    ds = tf.keras.utils.image_dataset_from_directory(\n",
        "        f\"{DATA_DIR}/{split}\", image_size=IMG_SIZE, batch_size=BATCH,\n",
        "        label_mode=\"binary\", shuffle=shuffle, interpolation=\"bilinear\") # Menggunakan bilinear interpolation\n",
        "\n",
        "    # Casting ke float32 untuk memastikan input siap sebelum Augmentasi/Preprocessing\n",
        "    ds = ds.map(lambda x,y:(tf.cast(x,tf.float32),y))\n",
        "    return ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "tr,va,te=ds(\"train\"), ds(\"val\",False), ds(\"test\",False)\n",
        "\n",
        "# --- 3. PEMBANGUNAN MODEL ---\n",
        "\n",
        "# 1. Definisikan layer Augmentasi (Lebih Kuat untuk Deepfake)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    # Peningkatan: Tambah variasi pencahayaan\n",
        "    layers.RandomBrightness(0.1, value_range=(0, 255)),\n",
        "    layers.RandomContrast(0.1),\n",
        "], name=\"data_augmentation\")\n",
        "\n",
        "base=Xception(weights=\"imagenet\", include_top=False, input_shape=IMG_SIZE+(3,))\n",
        "# base.trainable akan diatur di setiap Fase\n",
        "\n",
        "inp=layers.Input(shape=IMG_SIZE+(3,))\n",
        "x = data_augmentation(inp)   # Terapkan Augmentasi\n",
        "x = preprocess_input(x)      # Terapkan Preprocessing Xception\n",
        "x = base(x, training=False)  # Base model dibekukan untuk Phase 1\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x)   # Peningkatan: Dropout 0.5\n",
        "out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = models.Model(inp,out)\n",
        "\n",
        "# --- 4. CALLBACKS ---\n",
        "\n",
        "ck=ModelCheckpoint(f\"{MODEL_DIR}/xception_deepfake_best.keras\", save_best_only=True, monitor=\"val_auc\", mode=\"max\")\n",
        "es=EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_auc\", mode=\"max\")\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=5, min_lr=1e-6) # LR Scheduler\n",
        "\n",
        "# --- 5. PELATIHAN FASE 1: Training Head (Dibekukan) ---\n",
        "print(\"--- STARTING PHASE 1: Training Head (Freeze) ---\")\n",
        "\n",
        "base.trainable = False # Pastikan Xception dibekukan\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), # LR 1e-4\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[tf.keras.metrics.AUC(name=\"auc\"), \"accuracy\"])\n",
        "\n",
        "# Melatih 10 Epoch awal, hanya melatih head.\n",
        "history_phase1 = model.fit(tr, validation_data=va, epochs=10,\n",
        "                            callbacks=[ck, es, reduce_lr])\n",
        "\n",
        "# --- 6. PELATIHAN FASE 2: Fine Tuning (Dibuka) ---\n",
        "# Jika Early Stopping belum terpicu di Phase 1, kita lanjutkan.\n",
        "print(\"\\n--- STARTING PHASE 2: Fine Tuning Base Model (Unfreeze) ---\")\n",
        "\n",
        "base.trainable = True # Unfreeze Base Model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), # LR JAUH LEBIH KECIL (1e-5)\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[tf.keras.metrics.AUC(name=\"auc\"), \"accuracy\"])\n",
        "\n",
        "# Lanjutkan pelatihan, dimulai dari epoch terakhir Phase 1.\n",
        "initial_epoch = len(history_phase1.history['loss'])\n",
        "model.fit(tr, validation_data=va, epochs=EPOCHS, initial_epoch=initial_epoch,\n",
        "          callbacks=[ck, es, reduce_lr])\n",
        "\n",
        "# --- 7. EVALUASI DAN SIMPAN AKHIR ---\n",
        "\n",
        "# Muat bobot terbaik yang disimpan oleh ModelCheckpoint\n",
        "best_model = tf.keras.models.load_model(f\"{MODEL_DIR}/xception_deepfake_best.keras\")\n",
        "\n",
        "print(\"TEST:\", best_model.evaluate(te, return_dict=True))\n",
        "\n",
        "# Perbaikan Wajib: Simpan model terbaik dalam format .keras\n",
        "best_model.save(f\"{MODEL_DIR}/xception_deepfake_final.keras\")"
      ],
      "metadata": {
        "id": "l1j2XVbZvfxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"DATA_DIR\"] = \"/content/project/data_crops\"\n",
        "os.environ[\"MODEL_DIR\"] = \"/content/project/models\"\n",
        "\n",
        "%run -i train_xception_tf.py\n"
      ],
      "metadata": {
        "id": "zrSsqfTSxyi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf, numpy as np, cv2, glob, os\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "\n",
        "MODEL=\"/content/project/models/xception_deepfake.h5\"\n",
        "assert os.path.exists(MODEL), \"Model belum ada. Pastikan training selesai.\"\n",
        "model=tf.keras.models.load_model(MODEL)\n",
        "\n",
        "cands=glob.glob(\"/content/project/data_crops/test/real/*.jpg\")+glob.glob(\"/content/project/data_crops/test/fake/*.jpg\")\n",
        "assert cands, \"Tidak ada sampel test.\"\n",
        "img_path=cands[0]\n",
        "img=cv2.imread(img_path)[:,:,::-1]; img=cv2.resize(img,(299,299))\n",
        "x=np.expand_dims(img.astype(np.float32),0); x=preprocess_input(x)\n",
        "p=float(model.predict(x, verbose=0)[0][0])\n",
        "print(os.path.basename(img_path), \"| fake_prob:\", round(p,4), \"| pred:\", \"FAKE\" if p>=0.5 else \"REAL\")\n"
      ],
      "metadata": {
        "id": "52k90fCjvhS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7J9ft-yLvi7e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}